{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cf_xarray  # noqa: F401\n",
    "import dask.array\n",
    "import geoarrow.rust.core as geoarrow\n",
    "import numpy as np\n",
    "import shapely\n",
    "import xarray as xr\n",
    "\n",
    "import grid_indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounds_to_polygons(lon, lat):\n",
    "    vertices = xr.concat([lon, lat], dim=\"coords\")\n",
    "\n",
    "    return xr.apply_ufunc(\n",
    "        shapely.polygons,\n",
    "        vertices.chunk({\"coords\": -1}),\n",
    "        input_core_dims=[[\"bounds\", \"coords\"]],\n",
    "        output_core_dims=[[]],\n",
    "        dask=\"parallelized\",\n",
    "        keep_attrs=False,\n",
    "        output_dtypes=[object],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_grid = (\n",
    "    grid_indexing.tutorial.generate_grid(\"2d-curvilinear\", resolution=\"large\")\n",
    "    .cf.add_bounds([\"latitude\", \"longitude\"])\n",
    "    .chunk({\"x\": 600, \"y\": 300})\n",
    "    .assign_coords(\n",
    "        geometry=lambda ds: bounds_to_polygons(ds[\"lon_bounds\"], ds[\"lat_bounds\"])\n",
    "    )\n",
    ")\n",
    "source_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### procedure\n",
    "\n",
    "1. creation of the distributed rtree\n",
    "   - values:\n",
    "        - the cell boundaries as geometries\n",
    "        - and from that, the chunk boundaries\n",
    "    - create and index from the chunk boundaries and save it\n",
    "    - for each chunk of cell boundaries, create an index (as a delayed function? needs to pickle for that, though)\n",
    "2. query the index\n",
    "    - extract the chunk boundaries from the input\n",
    "    - query the chunk boundary index to figure out which chunks a target chunk interacts with\n",
    "    - query the interacting chunk's index\n",
    "    - assemble the result as a sparse matrix\n",
    "\n",
    "### issues\n",
    "\n",
    "- for dask to work, the trees have to be pickle-able\n",
    "- going from a grid of tasks to a concatenated sparse matrix may be tricky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_grid = (\n",
    "    grid_indexing.tutorial.generate_grid(\"2d-rectilinear\", \"small\")\n",
    "    .cf.add_bounds([\"latitude\", \"longitude\"])\n",
    "    .chunk({\"y\": 30, \"x\": 60})\n",
    "    .assign_coords(\n",
    "        geometry=lambda ds: bounds_to_polygons(ds[\"lon_bounds\"], ds[\"lat_bounds\"])\n",
    "    )\n",
    ")\n",
    "target_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_boundaries(chunks):\n",
    "    coverage_ = dask.delayed(shapely.coverage_union_all)\n",
    "\n",
    "    return list(map(coverage_, chunks))\n",
    "\n",
    "\n",
    "def index_from_shapely(chunk):\n",
    "    return grid_indexing.Index(geoarrow.from_shapely(chunk.flatten()))\n",
    "\n",
    "\n",
    "def _query_overlap(index, chunk):\n",
    "    result = index.query_overlap(geoarrow.from_shapely(chunk.flatten()))\n",
    "\n",
    "    if result.nnz == 0:\n",
    "        return None\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class DistributedRTree:\n",
    "    def __init__(self, grid):\n",
    "        chunk_grid = grid[\"geometry\"].data.to_delayed()\n",
    "\n",
    "        self.chunk_grid_shape = chunk_grid.shape\n",
    "\n",
    "        self.chunks = chunk_grid.flatten()\n",
    "        [boundaries] = dask.compute(chunk_boundaries(self.chunks))\n",
    "\n",
    "        self.chunk_indexes = list(map(dask.delayed(index_from_shapely), self.chunks))\n",
    "        self.index = grid_indexing.Index.from_shapely(np.array(boundaries))\n",
    "\n",
    "    def query_overlap(self, grid):\n",
    "        chunk_grid = grid[\"geometry\"].data.to_delayed()\n",
    "        chunks = chunk_grid.flatten()\n",
    "\n",
    "        # query overlapping indices\n",
    "        [boundaries] = dask.compute(chunk_boundaries(chunks))\n",
    "        geoms = geoarrow.from_shapely(np.array(boundaries))\n",
    "        overlapping_chunks = self.index.query_overlap(geoms).todense()\n",
    "\n",
    "        # actual distributed query\n",
    "        tasks = np.full_like(overlapping_chunks, dtype=object, fill_value=None)\n",
    "        for target_index, chunk in enumerate(chunks):\n",
    "            [source_indices] = np.nonzero(overlapping_chunks[target_index])\n",
    "\n",
    "            tasks[target_index, source_indices] = np.array(\n",
    "                [\n",
    "                    dask.delayed(_query_overlap)(\n",
    "                        self.chunk_indexes[source_index], chunks[target_index]\n",
    "                    )\n",
    "                    for source_index in source_indices\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return tasks\n",
    "\n",
    "\n",
    "dtree = DistributedRTree(source_grid)\n",
    "dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dtree.query_overlap(target_grid)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dask.compute(result.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "geoms = grid_indexing.infer_cell_geometries(source_grid)\n",
    "geoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "index = grid_indexing.Index(geoms)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "target_geoms = grid_indexing.infer_cell_geometries(target_grid)\n",
    "target_geoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "overlaps = index.query_overlap(target_geoms)\n",
    "overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
